# Models state

Get the current models state:

- `/model/state` *GET*: the current state of the models on the server

## Example

```bash
curl 0.0.0.0:5143/model/state -H 'Authorization: Bearer 67b164c5862183d9cce2e185b3e79bca58b915284ec7fc347a08ca69f07e466b' | python -m json.tool
```

```json
[
    {
        "id": 1,
        "jsonrpc": "2.0",
        "result": {
            "args": [
                "--host",
                "127.0.0.1",
                "--port",
                "8080",
                "--props",
                "--no-webui",
                "-t",
                "8",
                "-tb",
                "16",
                "-m",
                "models/UIGEN-T3-14B-Preview-Q8_0-GGUF_q8_0.gguf",
                "-c",
                "2048",
                "--log-colors",
                "--no-warmup"
            ],
            "conf": {
                "exe_path": "./llama-server",
                "model_pathname": "models/UIGEN-T3-14B-Preview-Q8_0-GGUF_q8_0.gguf",
                "pathname_type": 0,
                "ctx": 2048,
                "threads": 8,
                "t_prompt_proc": 16,
                "args": [
                    "--log-colors",
                    "--no-warmup"
                ]
            },
            "exe": "./llama-server",
            "running": true,
            "start_count": 1,
            "uptime": "duration: 4s"
        }
    },
    {
        "id": 2,
        "jsonrpc": "2.0",
        "result": [
            "UIGEN-T3-14B-Preview-Q8_0-GGUF_q8_0.gguf",
            "qwen2.5-coder_14b-instruct-q8_0_Q8_0.gguf",
            "mistralai_Mistral-Small-3.2-24B-Instruct-2506-Q5_K_S.gguf",
            "Devstral-Small-2507-UD-Q5_K_XL.gguf"
        ]
    }
]
```

## Description

The endpoint `/model/state` is JSON-RPC 2.0 compliant.

The response is an array of two JSON-RPC messages:

1. The first message provides information about the eventual running `llama-server`.

2. The second one lists the available models.
