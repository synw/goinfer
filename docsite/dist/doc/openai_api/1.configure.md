# Configure the OpenAi api

To enable this api add a section in `goinfer.json`:

```js
{
    "api_key": "your_openai_api_key",
    "oai": {
        "enable": true,
        "threads": 4,
        "template": "{system}\n\n### Instruction: {prompt}\n\n### Response:"
    }
}
```

## Parameters:

- `threads` *number*: the numbers of threads to use for Llama.cpp
- `template` *string*: the template to use for system and user roles, see below

## Template

The template maps the `messages` payload for the `/v1/chat/completions` endpoint. Example payload:

```js
{
  "model": "gpt-3.5-turbo",
  "messages": [
    {
      "role": "system",
      "content": "You are a helpful assistant."
    },
    {
      "role": "user",
      "content": "this is the prompt content"
    }
  ]
}
```

For this template:

```
{system}\n\n### Instruction: {prompt}\n\n### Response:
```

It will create this final prompt for Llama.cpp:

```
You are a helpful assistant.

### Instruction: this is the prompt content

### Response:
```